{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adasilva70/langchain-tutorial/blob/main/notebooks/introduction-langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vL-1eM-FRl_3",
    "outputId": "a4ca9bc3-dcc6-489f-c839-ff682e37fcae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0.post1\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.8.30)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=7742d4c2f3d065fd08381e39b3ea333b033241e56292aa265d073db572845850\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "# # uncomment and run below:\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-openai\n",
    "%pip install tiktoken\n",
    "%pip install faiss-cpu\n",
    "%pip install beautifulsoup4\n",
    "%pip install google-search-results\n",
    "%pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YP1SNpncdNfw",
    "outputId": "eb51afd5-08c6-47df-dc22-aef1f753389d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: ··········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Set OPENAI API Key\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yc8jhWPzdewK"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jChE8udXdq4g"
   },
   "outputs": [],
   "source": [
    "MODEL='gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u0CdlCvtdsXA"
   },
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(model=MODEL, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqB2ewcjdsH5",
    "outputId": "0a8c7e9e-869a-4b6a-ba38-adc7a70c7fb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's great to hear! As a Solutions Architect with Portworx, you likely have a deep understanding of cloud-native storage solutions and how they integrate with container orchestration platforms like Kubernetes. If you have any specific questions or topics you'd like to discuss—whether it's about best practices, architecture design, or anything else related to your role—feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 16, 'total_tokens': 88, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-5cadeda3-d010-45fa-b9ed-aaf5e6d42428-0', usage_metadata={'input_tokens': 16, 'output_tokens': 72, 'total_tokens': 88, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chat_model.invoke(\"I am Solutions Architect with Portworx!\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "_I9UCA_MeF2A",
    "outputId": "ad6340e8-8ed5-421a-e097-893af01a26df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
       "\n",
       "AIMessage is returned from a chat model as a response to a prompt.\n",
       "\n",
       "This message represents the output of the model and consists of both\n",
       "the raw output as returned by the model together standardized fields\n",
       "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 141);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "AxLV-g0HeFo-",
    "outputId": "abde2488-f3b1-4bdd-abd9-bf885514dc54"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"That's great to hear! As a Solutions Architect with Portworx, you likely have a deep understanding of cloud-native storage solutions and how they integrate with container orchestration platforms like Kubernetes. If you have any specific questions or topics you'd like to discuss—whether it's about best practices, architecture design, or anything else related to your role—feel free to ask!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EXa-r4J-eQmk"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Jy1JOwS_eXse",
    "outputId": "c69796b3-a0d1-4034-9371-a478c3dec673"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Human: Show me 5 examples of this concept: animal'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Show me 5 examples of this concept: {concept}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt.format(concept=\"animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "65gApEjjehnX",
    "outputId": "0a68be91-735e-44d6-ba0a-c42d1fd72359"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Human: Show me 5 examples of this concept: movies'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(concept=\"movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rTC1MUcxen_t"
   },
   "outputs": [],
   "source": [
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "4Psa1X2sfDy5",
    "outputId": "6eea54a6-224b-48c0-8474-d88cec27f73d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.runnables.base.RunnableSequence</b><br/>def __init__(*steps: RunnableLike, name: Optional[str]=None, first: Optional[Runnable[Any, Any]]=None, middle: Optional[list[Runnable[Any, Any]]]=None, last: Optional[Runnable[Any, Any]]=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py</a>Sequence of Runnables, where the output of each is the input of the next.\n",
       "\n",
       "**RunnableSequence** is the most important composition operator in LangChain\n",
       "as it is used in virtually every chain.\n",
       "\n",
       "A RunnableSequence can be instantiated directly or more commonly by using the `|`\n",
       "operator where either the left or right operands (or both) must be a Runnable.\n",
       "\n",
       "Any RunnableSequence automatically supports sync, async, batch.\n",
       "\n",
       "The default implementations of `batch` and `abatch` utilize threadpools and\n",
       "asyncio gather and will be faster than naive invocation of invoke or ainvoke\n",
       "for IO bound Runnables.\n",
       "\n",
       "Batching is implemented by invoking the batch method on each component of the\n",
       "RunnableSequence in order.\n",
       "\n",
       "A RunnableSequence preserves the streaming properties of its components, so if all\n",
       "components of the sequence implement a `transform` method -- which\n",
       "is the method that implements the logic to map a streaming input to a streaming\n",
       "output -- then the sequence will be able to stream input to output!\n",
       "\n",
       "If any component of the sequence does not implement transform then the\n",
       "streaming will only begin after this component is run. If there are\n",
       "multiple blocking components, streaming begins after the last one.\n",
       "\n",
       "Please note: RunnableLambdas do not support `transform` by default! So if\n",
       "    you need to use a RunnableLambdas be careful about where you place them in a\n",
       "    RunnableSequence (if you need to use the .stream()/.astream() methods).\n",
       "\n",
       "    If you need arbitrary logic and need streaming, you can subclass\n",
       "    Runnable, and implement `transform` for whatever logic you need.\n",
       "\n",
       "Here is a simple example that uses simple functions to illustrate the use of\n",
       "RunnableSequence:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain_core.runnables import RunnableLambda\n",
       "\n",
       "        def add_one(x: int) -&gt; int:\n",
       "            return x + 1\n",
       "\n",
       "        def mul_two(x: int) -&gt; int:\n",
       "            return x * 2\n",
       "\n",
       "        runnable_1 = RunnableLambda(add_one)\n",
       "        runnable_2 = RunnableLambda(mul_two)\n",
       "        sequence = runnable_1 | runnable_2\n",
       "        # Or equivalently:\n",
       "        # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
       "        sequence.invoke(1)\n",
       "        await sequence.ainvoke(1)\n",
       "\n",
       "        sequence.batch([1, 2, 3])\n",
       "        await sequence.abatch([1, 2, 3])\n",
       "\n",
       "Here&#x27;s an example that uses streams JSON output generated by an LLM:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain_core.output_parsers.json import SimpleJsonOutputParser\n",
       "        from langchain_openai import ChatOpenAI\n",
       "\n",
       "        prompt = PromptTemplate.from_template(\n",
       "            &#x27;In JSON format, give me a list of {topic} and their &#x27;\n",
       "            &#x27;corresponding names in French, Spanish and in a &#x27;\n",
       "            &#x27;Cat Language.&#x27;\n",
       "        )\n",
       "\n",
       "        model = ChatOpenAI()\n",
       "        chain = prompt | model | SimpleJsonOutputParser()\n",
       "\n",
       "        async for chunk in chain.astream({&#x27;topic&#x27;: &#x27;colors&#x27;}):\n",
       "            print(&#x27;-&#x27;)  # noqa: T201\n",
       "            print(chunk, sep=&#x27;&#x27;, flush=True)  # noqa: T201</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 2659);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kFxOgUUmfItv"
   },
   "outputs": [],
   "source": [
    "output = chain.invoke({\"concept\": \"movies\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "igw3-tw4fPpf",
    "outputId": "71965e45-4055-47c7-89e2-625bb327a7cc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Sure! Here are five examples of different movie genres:\\n\\n1. **Action**: *Mad Max: Fury Road* (2015) - A high-octane post-apocalyptic film featuring intense car chases and explosive action sequences.\\n\\n2. **Romantic Comedy**: *When Harry Met Sally...* (1989) - A classic film that explores the complexities of friendship and love through witty dialogue and charming performances.\\n\\n3. **Science Fiction**: *Inception* (2010) - A mind-bending thriller that delves into the world of dreams and subconscious manipulation, featuring stunning visuals and a complex narrative.\\n\\n4. **Horror**: *Get Out* (2017) - A socially conscious horror film that combines suspense and satire, focusing on racial tensions and psychological manipulation.\\n\\n5. **Animated**: *Spider-Man: Into the Spider-Verse* (2018) - A groundbreaking animated film that introduces multiple Spider-People from different dimensions, celebrated for its unique animation style and storytelling.\\n\\nLet me know if you need more examples or information!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_yVFivHxfcQi"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "ktf2i4vpffjY",
    "outputId": "a765ca58-e64a-4f5e-978b-ac8084044df4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Here are five examples of different movie genres:\n",
       "\n",
       "1. **Action**: *Mad Max: Fury Road* (2015) - A high-octane post-apocalyptic film featuring intense car chases and explosive action sequences.\n",
       "\n",
       "2. **Romantic Comedy**: *When Harry Met Sally...* (1989) - A classic film that explores the complexities of friendship and love through witty dialogue and charming performances.\n",
       "\n",
       "3. **Science Fiction**: *Inception* (2010) - A mind-bending thriller that delves into the world of dreams and subconscious manipulation, featuring stunning visuals and a complex narrative.\n",
       "\n",
       "4. **Horror**: *Get Out* (2017) - A socially conscious horror film that combines suspense and satire, focusing on racial tensions and psychological manipulation.\n",
       "\n",
       "5. **Animated**: *Spider-Man: Into the Spider-Verse* (2018) - A groundbreaking animated film that introduces multiple Spider-People from different dimensions, celebrated for its unique animation style and storytelling.\n",
       "\n",
       "Let me know if you need more examples or information!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3-4nLdAfkwT",
    "outputId": "755d55ef-9a05-4a36-b505-c64228caa666"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Here are five examples of different movie genres:\\n\\n1. **Action**: *Mad Max: Fury Road* (2015) - A high-octane post-apocalyptic film featuring intense car chases and explosive action sequences.\\n\\n2. **Romantic Comedy**: *When Harry Met Sally...* (1989) - A classic film that explores the complexities of friendship and love through witty dialogue and charming performances.\\n\\n3. **Science Fiction**: *Inception* (2010) - A mind-bending thriller that delves into the world of dreams and subconscious manipulation, featuring stunning visuals and a complex narrative.\\n\\n4. **Horror**: *Get Out* (2017) - A socially conscious horror film that combines suspense and satire, focusing on racial tensions and psychological manipulation.\\n\\n5. **Animated**: *Spider-Man: Into the Spider-Verse* (2018) - A groundbreaking animated film that introduces multiple Spider-People from different dimensions, celebrated for its unique animation style and storytelling.\\n\\nLet me know if you need more examples or information!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 218, 'prompt_tokens': 17, 'total_tokens': 235, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-b4dae422-b178-4673-b1ef-8b33e783076f-0', usage_metadata={'input_tokens': 17, 'output_tokens': 218, 'total_tokens': 235, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imzYa00PfoBr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNIBtlI0vtoEivIeaCrPFQT",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
